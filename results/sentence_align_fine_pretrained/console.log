Loaded config: {'data': {'batch_size': 64, 'image_size': 224, 'num_workers': 4, 'path': 'src/data/', 'seq_len': 16, 'vocab_size': 5000}, 'model': {'align_text_source': 'fine', 'backbone': 'vit_tiny_patch16_224', 'freeze_sentence_encoder': True, 'fusion_include_coarse': False, 'fusion_include_fine': False, 'fusion_include_image': True, 'latent_dim': 512, 'method_option': 'alignment', 'num_classes': 5, 'sentence_encoder_device': 'cuda', 'sentence_encoder_name': 'all-MiniLM-L6-v2', 'sentence_pretrained': True, 'use_coarse': False, 'use_fine': False, 'use_sentence_encoder': True}, 'project': {'name': 'FireDamageClassification', 'version': '1.0'}, 'training': {'align_temperature': 0.07, 'drop_path_rate': 0.1, 'dropout': 0.2, 'epochs': 70, 'lambda_align': 0.1, 'lambda_cls': 1.0, 'lambda_vae': 0.1, 'lr': '1e-4', 'weight_decay': '1e-3'}}
Results will be saved to: results/sentence_align_fine_pretrained
Using device: cuda
Model Type: method
Splitting by Region:
Train Regions: ['GLA', 'VAL', 'MOS', 'CAS', 'MIL', 'POST', 'CRE', 'DIN', 'MON', 'SCU', 'FOR', 'BEU']
Val Regions: ['BEA', 'AUG', 'ZOG']
Test Regions: ['CAL', 'FAI', 'DIX']
Scanning images in src/data/image for mode train...
Loaded 5393 samples for mode train
Scanning images in src/data/image for mode val...
Loaded 1316 samples for mode val
Scanning images in src/data/image for mode test...
Loaded 1122 samples for mode test
Calculating class weights for WeightedRandomSampler...
Train Class Counts: {1: 204, 0: 2281, 4: 766, 3: 2060, 2: 82}
Data loaded: Train=5393, Val=1316, Test=1122
Parameters: 12,129,223
FLOPs: 1083166208.0
Starting training loop...
Batch 0: Loss 1.7317 (Cls: 1.3098) LR: 0.000004
Batch 10: Loss 1.5920 (Cls: 1.1683) LR: 0.000004
Batch 20: Loss 1.5737 (Cls: 1.1501) LR: 0.000004
Batch 30: Loss 1.5556 (Cls: 1.1359) LR: 0.000004
Batch 40: Loss 1.6448 (Cls: 1.2241) LR: 0.000004
Batch 50: Loss 1.5416 (Cls: 1.1221) LR: 0.000004
Batch 60: Loss 1.5115 (Cls: 1.0901) LR: 0.000004
Batch 70: Loss 1.6198 (Cls: 1.1961) LR: 0.000004
Batch 80: Loss 1.6013 (Cls: 1.1789) LR: 0.000004
Epoch 1: Loss 1.5814, Acc 0.2097
Val Loss 1.6476, Val Acc 0.1824
New best model saved with Val Acc: 0.1824
Batch 0: Loss 1.5800 (Cls: 1.1595) LR: 0.000005
Batch 10: Loss 1.5968 (Cls: 1.1777) LR: 0.000005
Batch 20: Loss 1.5883 (Cls: 1.1720) LR: 0.000005
Batch 30: Loss 1.5025 (Cls: 1.0768) LR: 0.000005
Batch 40: Loss 1.5423 (Cls: 1.1243) LR: 0.000005
Batch 50: Loss 1.5541 (Cls: 1.1350) LR: 0.000005
Batch 60: Loss 1.5819 (Cls: 1.1611) LR: 0.000006
Batch 70: Loss 1.5810 (Cls: 1.1582) LR: 0.000006
Batch 80: Loss 1.6164 (Cls: 1.1945) LR: 0.000006
Epoch 2: Loss 1.5465, Acc 0.2125
Val Loss 1.6591, Val Acc 0.1702
Batch 0: Loss 1.5514 (Cls: 1.1280) LR: 0.000006
Batch 10: Loss 1.4430 (Cls: 1.0254) LR: 0.000006
Batch 20: Loss 1.5000 (Cls: 1.0768) LR: 0.000007
Batch 30: Loss 1.5809 (Cls: 1.1636) LR: 0.000007
Batch 40: Loss 1.4921 (Cls: 1.0722) LR: 0.000007
Batch 50: Loss 1.5962 (Cls: 1.1790) LR: 0.000008
Batch 60: Loss 1.4850 (Cls: 1.0652) LR: 0.000008
Batch 70: Loss 1.5787 (Cls: 1.1603) LR: 0.000008
Batch 80: Loss 1.5998 (Cls: 1.1796) LR: 0.000009
Epoch 3: Loss 1.5359, Acc 0.2147
Val Loss 1.5592, Val Acc 0.3404
New best model saved with Val Acc: 0.3404
Batch 0: Loss 1.5397 (Cls: 1.1223) LR: 0.000009
Batch 10: Loss 1.4947 (Cls: 1.0773) LR: 0.000009
Batch 20: Loss 1.5148 (Cls: 1.0974) LR: 0.000010
Batch 30: Loss 1.4725 (Cls: 1.0524) LR: 0.000010
Batch 40: Loss 1.5079 (Cls: 1.0937) LR: 0.000010
Batch 50: Loss 1.5814 (Cls: 1.1645) LR: 0.000011
Batch 60: Loss 1.5584 (Cls: 1.1392) LR: 0.000011
Batch 70: Loss 1.4848 (Cls: 1.0697) LR: 0.000012
Batch 80: Loss 1.5238 (Cls: 1.1019) LR: 0.000012
Epoch 4: Loss 1.5245, Acc 0.2303
Val Loss 1.5266, Val Acc 0.2850
Batch 0: Loss 1.5526 (Cls: 1.1353) LR: 0.000012
Batch 10: Loss 1.5672 (Cls: 1.1487) LR: 0.000013
Batch 20: Loss 1.5327 (Cls: 1.1203) LR: 0.000013
Batch 30: Loss 1.5294 (Cls: 1.1136) LR: 0.000014
Batch 40: Loss 1.4891 (Cls: 1.0801) LR: 0.000014
Batch 50: Loss 1.4859 (Cls: 1.0713) LR: 0.000015
Batch 60: Loss 1.4601 (Cls: 1.0489) LR: 0.000015
Batch 70: Loss 1.5476 (Cls: 1.1312) LR: 0.000016
Batch 80: Loss 1.5462 (Cls: 1.1309) LR: 0.000017
Epoch 5: Loss 1.5177, Acc 0.2284
Val Loss 1.5973, Val Acc 0.1733
Batch 0: Loss 1.5029 (Cls: 1.0874) LR: 0.000017
Batch 10: Loss 1.4130 (Cls: 0.9998) LR: 0.000017
Batch 20: Loss 1.5315 (Cls: 1.1160) LR: 0.000018
Batch 30: Loss 1.5137 (Cls: 1.0992) LR: 0.000019
Batch 40: Loss 1.5166 (Cls: 1.0958) LR: 0.000019
Batch 50: Loss 1.4444 (Cls: 1.0288) LR: 0.000020
Batch 60: Loss 1.5724 (Cls: 1.1546) LR: 0.000021
Batch 70: Loss 1.4717 (Cls: 1.0608) LR: 0.000021
Batch 80: Loss 1.5230 (Cls: 1.1129) LR: 0.000022
Epoch 6: Loss 1.5081, Acc 0.2266
Val Loss 1.5603, Val Acc 0.2591
Batch 0: Loss 1.5389 (Cls: 1.1225) LR: 0.000022
Batch 10: Loss 1.5238 (Cls: 1.1109) LR: 0.000023
Batch 20: Loss 1.5357 (Cls: 1.1191) LR: 0.000023
Batch 30: Loss 1.4426 (Cls: 1.0321) LR: 0.000024
Batch 40: Loss 1.5558 (Cls: 1.1408) LR: 0.000025
Batch 50: Loss 1.5236 (Cls: 1.1139) LR: 0.000026
Batch 60: Loss 1.4712 (Cls: 1.0611) LR: 0.000026
Batch 70: Loss 1.4828 (Cls: 1.0689) LR: 0.000027
Batch 80: Loss 1.4892 (Cls: 1.0739) LR: 0.000028
Epoch 7: Loss 1.4957, Acc 0.2500
Val Loss 1.5306, Val Acc 0.3989
New best model saved with Val Acc: 0.3989
Batch 0: Loss 1.6038 (Cls: 1.1922) LR: 0.000028
Batch 10: Loss 1.5473 (Cls: 1.1369) LR: 0.000029
Batch 20: Loss 1.6023 (Cls: 1.1867) LR: 0.000030
Batch 30: Loss 1.4746 (Cls: 1.0582) LR: 0.000030
Batch 40: Loss 1.4614 (Cls: 1.0567) LR: 0.000031
Batch 50: Loss 1.4020 (Cls: 0.9973) LR: 0.000032
Batch 60: Loss 1.4175 (Cls: 1.0080) LR: 0.000033
Batch 70: Loss 1.4333 (Cls: 1.0235) LR: 0.000033
Batch 80: Loss 1.4399 (Cls: 1.0350) LR: 0.000034
Epoch 8: Loss 1.4872, Acc 0.2618
Val Loss 1.4552, Val Acc 0.4863
New best model saved with Val Acc: 0.4863
Batch 0: Loss 1.4363 (Cls: 1.0367) LR: 0.000035
Batch 10: Loss 1.6056 (Cls: 1.1947) LR: 0.000035
Batch 20: Loss 1.4178 (Cls: 1.0180) LR: 0.000036
Batch 30: Loss 1.4611 (Cls: 1.0539) LR: 0.000037
Batch 40: Loss 1.4313 (Cls: 1.0388) LR: 0.000038
Batch 50: Loss 1.4351 (Cls: 1.0292) LR: 0.000039
Batch 60: Loss 1.5154 (Cls: 1.1125) LR: 0.000039
Batch 70: Loss 1.3987 (Cls: 1.0071) LR: 0.000040
Batch 80: Loss 1.4062 (Cls: 0.9977) LR: 0.000041
Epoch 9: Loss 1.4524, Acc 0.2893
Val Loss 1.4622, Val Acc 0.4711
Batch 0: Loss 1.4308 (Cls: 1.0368) LR: 0.000041
Batch 10: Loss 1.5058 (Cls: 1.1063) LR: 0.000042
Batch 20: Loss 1.4790 (Cls: 1.0785) LR: 0.000043
Batch 30: Loss 1.4857 (Cls: 1.0843) LR: 0.000044
Batch 40: Loss 1.4387 (Cls: 1.0432) LR: 0.000045
Batch 50: Loss 1.4147 (Cls: 1.0269) LR: 0.000046
Batch 60: Loss 1.3546 (Cls: 0.9659) LR: 0.000046
Batch 70: Loss 1.4089 (Cls: 1.0148) LR: 0.000047
Batch 80: Loss 1.4260 (Cls: 1.0315) LR: 0.000048
Epoch 10: Loss 1.4389, Acc 0.3074
Val Loss 1.5293, Val Acc 0.4255
Batch 0: Loss 1.4195 (Cls: 1.0268) LR: 0.000049
Batch 10: Loss 1.4334 (Cls: 1.0367) LR: 0.000049
Batch 20: Loss 1.4657 (Cls: 1.0608) LR: 0.000050
Batch 30: Loss 1.3761 (Cls: 0.9940) LR: 0.000051
Batch 40: Loss 1.3886 (Cls: 0.9991) LR: 0.000052
Batch 50: Loss 1.4325 (Cls: 1.0446) LR: 0.000053
Batch 60: Loss 1.4542 (Cls: 1.0606) LR: 0.000054
Batch 70: Loss 1.3279 (Cls: 0.9503) LR: 0.000054
Batch 80: Loss 1.4725 (Cls: 1.0686) LR: 0.000055
Epoch 11: Loss 1.4170, Acc 0.3345
Val Loss 1.4417, Val Acc 0.4422
Batch 0: Loss 1.4378 (Cls: 1.0417) LR: 0.000056
Batch 10: Loss 1.2799 (Cls: 0.8990) LR: 0.000057
Batch 20: Loss 1.3810 (Cls: 0.9925) LR: 0.000057
Batch 30: Loss 1.3942 (Cls: 1.0084) LR: 0.000058
Batch 40: Loss 1.3361 (Cls: 0.9578) LR: 0.000059
Batch 50: Loss 1.4348 (Cls: 1.0545) LR: 0.000060
Batch 60: Loss 1.3076 (Cls: 0.9320) LR: 0.000061
Batch 70: Loss 1.3604 (Cls: 0.9861) LR: 0.000062
Batch 80: Loss 1.3441 (Cls: 0.9631) LR: 0.000062
Epoch 12: Loss 1.3868, Acc 0.3471
Val Loss 1.4435, Val Acc 0.4871
New best model saved with Val Acc: 0.4871
Batch 0: Loss 1.3412 (Cls: 0.9547) LR: 0.000063
Batch 10: Loss 1.3528 (Cls: 0.9694) LR: 0.000064
Batch 20: Loss 1.3908 (Cls: 1.0202) LR: 0.000064
Batch 30: Loss 1.2704 (Cls: 0.9008) LR: 0.000065
Batch 40: Loss 1.2802 (Cls: 0.9043) LR: 0.000066
Batch 50: Loss 1.2683 (Cls: 0.9035) LR: 0.000067
Batch 60: Loss 1.3797 (Cls: 1.0010) LR: 0.000068
Batch 70: Loss 1.3610 (Cls: 0.9808) LR: 0.000068
Batch 80: Loss 1.3527 (Cls: 0.9767) LR: 0.000069
Epoch 13: Loss 1.3609, Acc 0.3721
Val Loss 1.3965, Val Acc 0.5144
New best model saved with Val Acc: 0.5144
Batch 0: Loss 1.3860 (Cls: 1.0192) LR: 0.000070
Batch 10: Loss 1.3422 (Cls: 0.9759) LR: 0.000070
Batch 20: Loss 1.2513 (Cls: 0.8891) LR: 0.000071
Batch 30: Loss 1.3979 (Cls: 1.0324) LR: 0.000072
Batch 40: Loss 1.3558 (Cls: 0.9826) LR: 0.000073
Batch 50: Loss 1.3626 (Cls: 0.9973) LR: 0.000074
Batch 60: Loss 1.3941 (Cls: 1.0141) LR: 0.000074
Batch 70: Loss 1.4176 (Cls: 1.0518) LR: 0.000075
Batch 80: Loss 1.2875 (Cls: 0.9243) LR: 0.000076
Epoch 14: Loss 1.3398, Acc 0.3896
Val Loss 1.4640, Val Acc 0.4924
Batch 0: Loss 1.3534 (Cls: 0.9816) LR: 0.000076
Batch 10: Loss 1.2486 (Cls: 0.8851) LR: 0.000077
Batch 20: Loss 1.3912 (Cls: 1.0193) LR: 0.000078
Batch 30: Loss 1.2406 (Cls: 0.8854) LR: 0.000078
Batch 40: Loss 1.3388 (Cls: 0.9717) LR: 0.000079
Batch 50: Loss 1.3794 (Cls: 1.0105) LR: 0.000080
Batch 60: Loss 1.2787 (Cls: 0.9257) LR: 0.000080
Batch 70: Loss 1.3065 (Cls: 0.9411) LR: 0.000081
Batch 80: Loss 1.3182 (Cls: 0.9504) LR: 0.000082
Epoch 15: Loss 1.3329, Acc 0.4076
Val Loss 1.4161, Val Acc 0.5198
New best model saved with Val Acc: 0.5198
Batch 0: Loss 1.3072 (Cls: 0.9334) LR: 0.000082
Batch 10: Loss 1.3902 (Cls: 1.0176) LR: 0.000083
Batch 20: Loss 1.2739 (Cls: 0.9185) LR: 0.000083
Batch 30: Loss 1.3368 (Cls: 0.9794) LR: 0.000084
Batch 40: Loss 1.3050 (Cls: 0.9401) LR: 0.000085
Batch 50: Loss 1.2401 (Cls: 0.8806) LR: 0.000085
Batch 60: Loss 1.2351 (Cls: 0.8915) LR: 0.000086
Batch 70: Loss 1.2550 (Cls: 0.8953) LR: 0.000086
Batch 80: Loss 1.3777 (Cls: 1.0056) LR: 0.000087
Epoch 16: Loss 1.3168, Acc 0.4055
Val Loss 1.4320, Val Acc 0.4552
Batch 0: Loss 1.2304 (Cls: 0.8794) LR: 0.000087
Batch 10: Loss 1.3729 (Cls: 1.0200) LR: 0.000088
Batch 20: Loss 1.3110 (Cls: 0.9636) LR: 0.000088
Batch 30: Loss 1.2809 (Cls: 0.9413) LR: 0.000089
Batch 40: Loss 1.3015 (Cls: 0.9437) LR: 0.000089
Batch 50: Loss 1.2974 (Cls: 0.9502) LR: 0.000090
Batch 60: Loss 1.3270 (Cls: 0.9804) LR: 0.000091
Batch 70: Loss 1.3312 (Cls: 0.9800) LR: 0.000091
Batch 80: Loss 1.2939 (Cls: 0.9453) LR: 0.000092
Epoch 17: Loss 1.3192, Acc 0.4137
Val Loss 1.3827, Val Acc 0.5707
New best model saved with Val Acc: 0.5707
Batch 0: Loss 1.2475 (Cls: 0.9117) LR: 0.000092
Batch 10: Loss 1.3937 (Cls: 1.0257) LR: 0.000092
Batch 20: Loss 1.2980 (Cls: 0.9498) LR: 0.000093
Batch 30: Loss 1.3120 (Cls: 0.9466) LR: 0.000093
Batch 40: Loss 1.2748 (Cls: 0.9245) LR: 0.000094
Batch 50: Loss 1.2580 (Cls: 0.9221) LR: 0.000094
Batch 60: Loss 1.2775 (Cls: 0.9358) LR: 0.000094
Batch 70: Loss 1.3007 (Cls: 0.9538) LR: 0.000095
Batch 80: Loss 1.2223 (Cls: 0.8836) LR: 0.000095
Epoch 18: Loss 1.2982, Acc 0.4187
Val Loss 1.3532, Val Acc 0.5684
Batch 0: Loss 1.3160 (Cls: 0.9540) LR: 0.000095
Batch 10: Loss 1.3353 (Cls: 0.9873) LR: 0.000096
Batch 20: Loss 1.3127 (Cls: 0.9704) LR: 0.000096
Batch 30: Loss 1.3575 (Cls: 1.0032) LR: 0.000096
Batch 40: Loss 1.2945 (Cls: 0.9632) LR: 0.000097
Batch 50: Loss 1.3214 (Cls: 0.9790) LR: 0.000097
Batch 60: Loss 1.3027 (Cls: 0.9617) LR: 0.000097
Batch 70: Loss 1.3458 (Cls: 0.9898) LR: 0.000098
Batch 80: Loss 1.2524 (Cls: 0.9159) LR: 0.000098
Epoch 19: Loss 1.2915, Acc 0.4172
Val Loss 1.3831, Val Acc 0.5608
Batch 0: Loss 1.3904 (Cls: 1.0323) LR: 0.000098
Batch 10: Loss 1.3764 (Cls: 1.0297) LR: 0.000098
Batch 20: Loss 1.3282 (Cls: 0.9700) LR: 0.000098
Batch 30: Loss 1.2707 (Cls: 0.9338) LR: 0.000099
Batch 40: Loss 1.1832 (Cls: 0.8704) LR: 0.000099
Batch 50: Loss 1.2389 (Cls: 0.9057) LR: 0.000099
Batch 60: Loss 1.2148 (Cls: 0.9067) LR: 0.000099
Batch 70: Loss 1.2324 (Cls: 0.9139) LR: 0.000099
Batch 80: Loss 1.2389 (Cls: 0.9166) LR: 0.000099
Epoch 20: Loss 1.2781, Acc 0.4461
Val Loss 1.3936, Val Acc 0.5152
Batch 0: Loss 1.2547 (Cls: 0.9240) LR: 0.000099
Batch 10: Loss 1.3206 (Cls: 0.9703) LR: 0.000100
Batch 20: Loss 1.4322 (Cls: 1.0875) LR: 0.000100
Batch 30: Loss 1.2848 (Cls: 0.9459) LR: 0.000100
Batch 40: Loss 1.2413 (Cls: 0.9029) LR: 0.000100
Batch 50: Loss 1.3116 (Cls: 0.9449) LR: 0.000100
Batch 60: Loss 1.3222 (Cls: 0.9763) LR: 0.000100
Batch 70: Loss 1.2615 (Cls: 0.9420) LR: 0.000100
Batch 80: Loss 1.2889 (Cls: 0.9583) LR: 0.000100
Epoch 21: Loss 1.2844, Acc 0.4248
Val Loss 1.4173, Val Acc 0.5008
Batch 0: Loss 1.1792 (Cls: 0.8602) LR: 0.000100
Batch 10: Loss 1.2262 (Cls: 0.9019) LR: 0.000100
Batch 20: Loss 1.3360 (Cls: 0.9869) LR: 0.000100
Batch 30: Loss 1.2421 (Cls: 0.9245) LR: 0.000100
Batch 40: Loss 1.2358 (Cls: 0.8872) LR: 0.000100
Batch 50: Loss 1.2732 (Cls: 0.9414) LR: 0.000100
Batch 60: Loss 1.3109 (Cls: 0.9700) LR: 0.000100
Batch 70: Loss 1.3142 (Cls: 0.9652) LR: 0.000100
Batch 80: Loss 1.2613 (Cls: 0.9125) LR: 0.000100
Epoch 22: Loss 1.2600, Acc 0.4472
Val Loss 1.4037, Val Acc 0.5327
Batch 0: Loss 1.2730 (Cls: 0.9555) LR: 0.000100
Batch 10: Loss 1.3160 (Cls: 0.9834) LR: 0.000100
Batch 20: Loss 1.2641 (Cls: 0.9280) LR: 0.000100
Batch 30: Loss 1.2289 (Cls: 0.9058) LR: 0.000100
Batch 40: Loss 1.2947 (Cls: 0.9517) LR: 0.000100
Batch 50: Loss 1.1474 (Cls: 0.8394) LR: 0.000100
Batch 60: Loss 1.2432 (Cls: 0.9282) LR: 0.000100
Batch 70: Loss 1.2237 (Cls: 0.8837) LR: 0.000100
Batch 80: Loss 1.3368 (Cls: 1.0059) LR: 0.000100
Epoch 23: Loss 1.2518, Acc 0.4508
Val Loss 1.3106, Val Acc 0.6117
New best model saved with Val Acc: 0.6117
Batch 0: Loss 1.2336 (Cls: 0.8988) LR: 0.000100
Batch 10: Loss 1.2677 (Cls: 0.9285) LR: 0.000100
Batch 20: Loss 1.1591 (Cls: 0.8414) LR: 0.000099
Batch 30: Loss 1.3499 (Cls: 1.0110) LR: 0.000099
Batch 40: Loss 1.1960 (Cls: 0.8821) LR: 0.000099
Batch 50: Loss 1.2094 (Cls: 0.8810) LR: 0.000099
Batch 60: Loss 1.2851 (Cls: 0.9493) LR: 0.000099
Batch 70: Loss 1.3306 (Cls: 0.9921) LR: 0.000099
Batch 80: Loss 1.2592 (Cls: 0.9179) LR: 0.000099
Epoch 24: Loss 1.2458, Acc 0.4595
Val Loss 1.3045, Val Acc 0.5866
Batch 0: Loss 1.2811 (Cls: 0.9679) LR: 0.000099
Batch 10: Loss 1.1831 (Cls: 0.8871) LR: 0.000099
Batch 20: Loss 1.2400 (Cls: 0.9049) LR: 0.000099
Batch 30: Loss 1.2322 (Cls: 0.9395) LR: 0.000099
Batch 40: Loss 1.2405 (Cls: 0.9284) LR: 0.000099
Batch 50: Loss 1.2389 (Cls: 0.9194) LR: 0.000099
Batch 60: Loss 1.1680 (Cls: 0.8657) LR: 0.000099
Batch 70: Loss 1.2084 (Cls: 0.8909) LR: 0.000098
Batch 80: Loss 1.2097 (Cls: 0.9053) LR: 0.000098
Epoch 25: Loss 1.2262, Acc 0.4725
Val Loss 1.3531, Val Acc 0.5410
Batch 0: Loss 1.2112 (Cls: 0.8982) LR: 0.000098
Batch 10: Loss 1.2559 (Cls: 0.9398) LR: 0.000098
Batch 20: Loss 1.2516 (Cls: 0.9265) LR: 0.000098
Batch 30: Loss 1.2317 (Cls: 0.9255) LR: 0.000098
Batch 40: Loss 1.2213 (Cls: 0.9258) LR: 0.000098
Batch 50: Loss 1.2965 (Cls: 0.9677) LR: 0.000098
Batch 60: Loss 1.1603 (Cls: 0.8643) LR: 0.000098
Batch 70: Loss 1.3776 (Cls: 1.0443) LR: 0.000098
Batch 80: Loss 1.1820 (Cls: 0.9019) LR: 0.000097
Epoch 26: Loss 1.2092, Acc 0.4717
Val Loss 1.3036, Val Acc 0.6155
New best model saved with Val Acc: 0.6155
Batch 0: Loss 1.1928 (Cls: 0.9090) LR: 0.000097
Batch 10: Loss 1.2215 (Cls: 0.9166) LR: 0.000097
Batch 20: Loss 1.1157 (Cls: 0.8225) LR: 0.000097
Batch 30: Loss 1.1854 (Cls: 0.8764) LR: 0.000097
Batch 40: Loss 1.1036 (Cls: 0.8099) LR: 0.000097
Batch 50: Loss 1.1531 (Cls: 0.8456) LR: 0.000097
Batch 60: Loss 1.1596 (Cls: 0.8807) LR: 0.000097
Batch 70: Loss 1.2278 (Cls: 0.9324) LR: 0.000097
Batch 80: Loss 1.2844 (Cls: 0.9550) LR: 0.000096
Epoch 27: Loss 1.2050, Acc 0.4834
Val Loss 1.3492, Val Acc 0.5585
Batch 0: Loss 1.2480 (Cls: 0.9339) LR: 0.000096
Batch 10: Loss 1.1506 (Cls: 0.8573) LR: 0.000096
Batch 20: Loss 1.2663 (Cls: 0.9353) LR: 0.000096
Batch 30: Loss 1.1568 (Cls: 0.8631) LR: 0.000096
Batch 40: Loss 1.2483 (Cls: 0.9425) LR: 0.000096
Batch 50: Loss 1.2295 (Cls: 0.9175) LR: 0.000096
Batch 60: Loss 1.2236 (Cls: 0.9383) LR: 0.000095
Batch 70: Loss 1.1454 (Cls: 0.8442) LR: 0.000095
Batch 80: Loss 1.1984 (Cls: 0.8956) LR: 0.000095
Epoch 28: Loss 1.2076, Acc 0.4905
Val Loss 1.4023, Val Acc 0.5106
Batch 0: Loss 1.1804 (Cls: 0.8769) LR: 0.000095
Batch 10: Loss 1.1096 (Cls: 0.8105) LR: 0.000095
Batch 20: Loss 1.1024 (Cls: 0.8161) LR: 0.000095
Batch 30: Loss 1.1578 (Cls: 0.8582) LR: 0.000095
Batch 40: Loss 1.1372 (Cls: 0.8325) LR: 0.000094
Batch 50: Loss 1.0519 (Cls: 0.7625) LR: 0.000094
Batch 60: Loss 1.2289 (Cls: 0.9177) LR: 0.000094
Batch 70: Loss 1.2653 (Cls: 0.9405) LR: 0.000094
Batch 80: Loss 1.1608 (Cls: 0.8678) LR: 0.000094
Epoch 29: Loss 1.1927, Acc 0.5068
Val Loss 1.3614, Val Acc 0.5524
Batch 0: Loss 1.1507 (Cls: 0.8432) LR: 0.000094
Batch 10: Loss 1.1995 (Cls: 0.9001) LR: 0.000093
Batch 20: Loss 1.2534 (Cls: 0.9353) LR: 0.000093
Batch 30: Loss 1.2478 (Cls: 0.9393) LR: 0.000093
Batch 40: Loss 1.2204 (Cls: 0.8974) LR: 0.000093
Batch 50: Loss 1.0657 (Cls: 0.7842) LR: 0.000093
Batch 60: Loss 1.2358 (Cls: 0.9305) LR: 0.000092
Batch 70: Loss 1.2549 (Cls: 0.9306) LR: 0.000092
Batch 80: Loss 1.0844 (Cls: 0.8069) LR: 0.000092
Epoch 30: Loss 1.1753, Acc 0.5083
Val Loss 1.3367, Val Acc 0.5638
Batch 0: Loss 1.2984 (Cls: 0.9699) LR: 0.000092
Batch 10: Loss 1.2089 (Cls: 0.8946) LR: 0.000092
Batch 20: Loss 1.2039 (Cls: 0.8734) LR: 0.000091
Batch 30: Loss 1.2169 (Cls: 0.9069) LR: 0.000091
Batch 40: Loss 1.1392 (Cls: 0.8601) LR: 0.000091
Batch 50: Loss 1.1714 (Cls: 0.8836) LR: 0.000091
Batch 60: Loss 1.0950 (Cls: 0.7924) LR: 0.000091
Batch 70: Loss 1.1779 (Cls: 0.8595) LR: 0.000090
Batch 80: Loss 1.1440 (Cls: 0.8618) LR: 0.000090
Epoch 31: Loss 1.1802, Acc 0.5084
Val Loss 1.4817, Val Acc 0.4400
Batch 0: Loss 1.1607 (Cls: 0.8825) LR: 0.000090
Batch 10: Loss 1.1797 (Cls: 0.8971) LR: 0.000090
Batch 20: Loss 1.1454 (Cls: 0.8623) LR: 0.000090
Batch 30: Loss 1.0634 (Cls: 0.7696) LR: 0.000089
Batch 40: Loss 1.1838 (Cls: 0.8709) LR: 0.000089
Batch 50: Loss 1.1442 (Cls: 0.8368) LR: 0.000089
Batch 60: Loss 1.2307 (Cls: 0.9334) LR: 0.000089
Batch 70: Loss 1.1440 (Cls: 0.8485) LR: 0.000088
Batch 80: Loss 1.0535 (Cls: 0.7807) LR: 0.000088
Epoch 32: Loss 1.1665, Acc 0.5238
Val Loss 1.4636, Val Acc 0.5243
Batch 0: Loss 1.2200 (Cls: 0.9086) LR: 0.000088
Batch 10: Loss 1.1708 (Cls: 0.9074) LR: 0.000088
Batch 20: Loss 1.1034 (Cls: 0.8421) LR: 0.000088
Batch 30: Loss 1.1850 (Cls: 0.8820) LR: 0.000087
Batch 40: Loss 1.2000 (Cls: 0.8946) LR: 0.000087
Batch 50: Loss 1.1762 (Cls: 0.8744) LR: 0.000087
Batch 60: Loss 1.1323 (Cls: 0.8326) LR: 0.000087
Batch 70: Loss 1.1243 (Cls: 0.8418) LR: 0.000086
Batch 80: Loss 1.1235 (Cls: 0.8597) LR: 0.000086
Epoch 33: Loss 1.1700, Acc 0.5101
Val Loss 1.3286, Val Acc 0.5843
Batch 0: Loss 1.2210 (Cls: 0.9280) LR: 0.000086
Batch 10: Loss 1.0877 (Cls: 0.7916) LR: 0.000086
Batch 20: Loss 1.1975 (Cls: 0.9005) LR: 0.000085
Batch 30: Loss 1.1852 (Cls: 0.9018) LR: 0.000085
Batch 40: Loss 1.2111 (Cls: 0.9227) LR: 0.000085
Batch 50: Loss 1.0638 (Cls: 0.7708) LR: 0.000085
Batch 60: Loss 1.2245 (Cls: 0.9129) LR: 0.000084
Batch 70: Loss 1.2294 (Cls: 0.9535) LR: 0.000084
Batch 80: Loss 1.0725 (Cls: 0.8092) LR: 0.000084
Epoch 34: Loss 1.1535, Acc 0.5292
Val Loss 1.3254, Val Acc 0.5707
Batch 0: Loss 1.1647 (Cls: 0.8453) LR: 0.000084
Batch 10: Loss 1.1165 (Cls: 0.8348) LR: 0.000083
Batch 20: Loss 1.1262 (Cls: 0.8731) LR: 0.000083
Batch 30: Loss 1.3338 (Cls: 1.0044) LR: 0.000083
Batch 40: Loss 1.1221 (Cls: 0.8435) LR: 0.000082
Batch 50: Loss 1.0700 (Cls: 0.7616) LR: 0.000082
Batch 60: Loss 1.1009 (Cls: 0.8230) LR: 0.000082
Batch 70: Loss 1.0559 (Cls: 0.7747) LR: 0.000082
Batch 80: Loss 1.0677 (Cls: 0.7885) LR: 0.000081
Epoch 35: Loss 1.1321, Acc 0.5379
Val Loss 1.3066, Val Acc 0.5767
Batch 0: Loss 1.0961 (Cls: 0.8323) LR: 0.000081
Batch 10: Loss 1.2337 (Cls: 0.9351) LR: 0.000081
Batch 20: Loss 1.2765 (Cls: 0.9842) LR: 0.000081
Batch 30: Loss 1.1588 (Cls: 0.8938) LR: 0.000080
Batch 40: Loss 1.1383 (Cls: 0.8585) LR: 0.000080
Batch 50: Loss 1.1179 (Cls: 0.8579) LR: 0.000080
Batch 60: Loss 1.0377 (Cls: 0.7782) LR: 0.000079
Batch 70: Loss 1.2392 (Cls: 0.9457) LR: 0.000079
Batch 80: Loss 1.2064 (Cls: 0.9183) LR: 0.000079
Epoch 36: Loss 1.1315, Acc 0.5325
Val Loss 1.5652, Val Acc 0.3807
Batch 0: Loss 1.1813 (Cls: 0.8912) LR: 0.000079
Batch 10: Loss 1.1706 (Cls: 0.8745) LR: 0.000078
Batch 20: Loss 1.1343 (Cls: 0.8419) LR: 0.000078
Batch 30: Loss 1.1090 (Cls: 0.8396) LR: 0.000078
Batch 40: Loss 1.1027 (Cls: 0.8168) LR: 0.000077
Batch 50: Loss 1.1045 (Cls: 0.8464) LR: 0.000077
Batch 60: Loss 1.0879 (Cls: 0.8156) LR: 0.000077
Batch 70: Loss 1.2674 (Cls: 0.9383) LR: 0.000076
Batch 80: Loss 1.2421 (Cls: 0.9253) LR: 0.000076
Epoch 37: Loss 1.1385, Acc 0.5383
Val Loss 1.4438, Val Acc 0.4840
Batch 0: Loss 1.0612 (Cls: 0.7757) LR: 0.000076
Batch 10: Loss 1.0593 (Cls: 0.7832) LR: 0.000076
Batch 20: Loss 1.0148 (Cls: 0.7695) LR: 0.000075
Batch 30: Loss 1.2144 (Cls: 0.9256) LR: 0.000075
Batch 40: Loss 1.1253 (Cls: 0.8497) LR: 0.000075
Batch 50: Loss 1.0857 (Cls: 0.8231) LR: 0.000074
Batch 60: Loss 1.0326 (Cls: 0.7807) LR: 0.000074
Batch 70: Loss 1.0283 (Cls: 0.7843) LR: 0.000074
Batch 80: Loss 1.1685 (Cls: 0.8582) LR: 0.000073
Epoch 38: Loss 1.1111, Acc 0.5544
Val Loss 1.4308, Val Acc 0.5015
Batch 0: Loss 1.1350 (Cls: 0.8305) LR: 0.000073
Batch 10: Loss 1.1097 (Cls: 0.8427) LR: 0.000073
Batch 20: Loss 1.0986 (Cls: 0.8403) LR: 0.000072
Batch 30: Loss 1.1921 (Cls: 0.9088) LR: 0.000072
Batch 40: Loss 1.1429 (Cls: 0.8421) LR: 0.000072
Batch 50: Loss 1.1296 (Cls: 0.8578) LR: 0.000071
Batch 60: Loss 1.1727 (Cls: 0.8915) LR: 0.000071
Batch 70: Loss 1.0590 (Cls: 0.7875) LR: 0.000071
Batch 80: Loss 1.1900 (Cls: 0.9030) LR: 0.000070
Epoch 39: Loss 1.0914, Acc 0.5685
Val Loss 1.3215, Val Acc 0.5752
Batch 0: Loss 1.2595 (Cls: 0.9789) LR: 0.000070
Batch 10: Loss 1.0854 (Cls: 0.8241) LR: 0.000070
Batch 20: Loss 1.1096 (Cls: 0.8413) LR: 0.000069
Batch 30: Loss 1.1807 (Cls: 0.9045) LR: 0.000069
Batch 40: Loss 1.1567 (Cls: 0.8977) LR: 0.000069
Batch 50: Loss 1.1527 (Cls: 0.8939) LR: 0.000068
Batch 60: Loss 1.1232 (Cls: 0.8389) LR: 0.000068
Batch 70: Loss 1.1108 (Cls: 0.8519) LR: 0.000068
Batch 80: Loss 1.1242 (Cls: 0.8393) LR: 0.000067
Epoch 40: Loss 1.1149, Acc 0.5502
Val Loss 1.2914, Val Acc 0.6018
Batch 0: Loss 1.1090 (Cls: 0.8219) LR: 0.000067
Batch 10: Loss 1.1261 (Cls: 0.8650) LR: 0.000067
Batch 20: Loss 1.1147 (Cls: 0.8446) LR: 0.000066
Batch 30: Loss 1.0286 (Cls: 0.7527) LR: 0.000066
Batch 40: Loss 1.0471 (Cls: 0.7630) LR: 0.000066
Batch 50: Loss 1.0447 (Cls: 0.7816) LR: 0.000065
Batch 60: Loss 1.1278 (Cls: 0.8726) LR: 0.000065
Batch 70: Loss 1.0647 (Cls: 0.7834) LR: 0.000065
Batch 80: Loss 1.1300 (Cls: 0.8469) LR: 0.000064
Epoch 41: Loss 1.0843, Acc 0.5693
Val Loss 1.2749, Val Acc 0.6049
Batch 0: Loss 1.3711 (Cls: 1.0590) LR: 0.000064
Batch 10: Loss 1.0462 (Cls: 0.7872) LR: 0.000064
Batch 20: Loss 1.1405 (Cls: 0.8448) LR: 0.000063
Batch 30: Loss 1.0088 (Cls: 0.7570) LR: 0.000063
Batch 40: Loss 0.9987 (Cls: 0.7480) LR: 0.000063
Batch 50: Loss 1.1784 (Cls: 0.9035) LR: 0.000062
Batch 60: Loss 0.9975 (Cls: 0.7429) LR: 0.000062
Batch 70: Loss 1.2003 (Cls: 0.9202) LR: 0.000062
Batch 80: Loss 1.0361 (Cls: 0.7788) LR: 0.000061
Epoch 42: Loss 1.1025, Acc 0.5626
Val Loss 1.3477, Val Acc 0.5578
Batch 0: Loss 1.1627 (Cls: 0.8829) LR: 0.000061
Batch 10: Loss 1.1654 (Cls: 0.8495) LR: 0.000061
Batch 20: Loss 1.1117 (Cls: 0.8584) LR: 0.000060
Batch 30: Loss 1.1070 (Cls: 0.8334) LR: 0.000060
Batch 40: Loss 1.0255 (Cls: 0.7579) LR: 0.000060
Batch 50: Loss 1.1217 (Cls: 0.8656) LR: 0.000059
Batch 60: Loss 0.9268 (Cls: 0.6914) LR: 0.000059
Batch 70: Loss 0.9508 (Cls: 0.7118) LR: 0.000058
Batch 80: Loss 1.0565 (Cls: 0.8120) LR: 0.000058
Epoch 43: Loss 1.0694, Acc 0.5765
Val Loss 1.3141, Val Acc 0.6011
Batch 0: Loss 1.0948 (Cls: 0.8360) LR: 0.000058
Batch 10: Loss 0.9026 (Cls: 0.6887) LR: 0.000058
Batch 20: Loss 1.0442 (Cls: 0.7682) LR: 0.000057
Batch 30: Loss 1.0123 (Cls: 0.7700) LR: 0.000057
Batch 40: Loss 1.0921 (Cls: 0.8118) LR: 0.000056
Batch 50: Loss 1.0377 (Cls: 0.7756) LR: 0.000056
Batch 60: Loss 1.0541 (Cls: 0.7745) LR: 0.000056
Batch 70: Loss 0.9521 (Cls: 0.7075) LR: 0.000055
Batch 80: Loss 1.0296 (Cls: 0.7659) LR: 0.000055
Epoch 44: Loss 1.0651, Acc 0.5882
Val Loss 1.3190, Val Acc 0.5752
Batch 0: Loss 0.9847 (Cls: 0.7405) LR: 0.000055
Batch 10: Loss 1.0933 (Cls: 0.8122) LR: 0.000054
Batch 20: Loss 1.2662 (Cls: 0.9810) LR: 0.000054
Batch 30: Loss 1.0409 (Cls: 0.8059) LR: 0.000054
Batch 40: Loss 1.0401 (Cls: 0.7733) LR: 0.000053
Batch 50: Loss 0.9642 (Cls: 0.7258) LR: 0.000053
Batch 60: Loss 1.1907 (Cls: 0.8870) LR: 0.000052
Batch 70: Loss 1.0812 (Cls: 0.8175) LR: 0.000052
Batch 80: Loss 1.0754 (Cls: 0.8215) LR: 0.000052
Epoch 45: Loss 1.0686, Acc 0.5811
Val Loss 1.2573, Val Acc 0.6223
New best model saved with Val Acc: 0.6223
Batch 0: Loss 1.0701 (Cls: 0.7911) LR: 0.000052
Batch 10: Loss 1.0846 (Cls: 0.8016) LR: 0.000051
Batch 20: Loss 1.0617 (Cls: 0.7944) LR: 0.000051
Batch 30: Loss 0.9664 (Cls: 0.7211) LR: 0.000050
Batch 40: Loss 1.2049 (Cls: 0.9287) LR: 0.000050
Batch 50: Loss 1.0314 (Cls: 0.7968) LR: 0.000050
Batch 60: Loss 1.0177 (Cls: 0.7678) LR: 0.000049
Batch 70: Loss 1.1583 (Cls: 0.8835) LR: 0.000049
Batch 80: Loss 1.0293 (Cls: 0.7465) LR: 0.000049
Epoch 46: Loss 1.0489, Acc 0.5950
Val Loss 1.3776, Val Acc 0.5593
Batch 0: Loss 1.0437 (Cls: 0.7804) LR: 0.000048
Batch 10: Loss 1.0714 (Cls: 0.8409) LR: 0.000048
Batch 20: Loss 1.1712 (Cls: 0.8996) LR: 0.000048
Batch 30: Loss 1.0325 (Cls: 0.7764) LR: 0.000047
Batch 40: Loss 0.9656 (Cls: 0.7086) LR: 0.000047
Batch 50: Loss 1.0681 (Cls: 0.8098) LR: 0.000046
Batch 60: Loss 1.1853 (Cls: 0.8970) LR: 0.000046
Batch 70: Loss 0.9788 (Cls: 0.7332) LR: 0.000046
Batch 80: Loss 1.3382 (Cls: 1.0132) LR: 0.000045
Epoch 47: Loss 1.0598, Acc 0.5924
Val Loss 1.4177, Val Acc 0.4833
Batch 0: Loss 1.1215 (Cls: 0.8532) LR: 0.000045
Batch 10: Loss 1.0973 (Cls: 0.8297) LR: 0.000045
Batch 20: Loss 1.0720 (Cls: 0.8229) LR: 0.000044
Batch 30: Loss 1.1240 (Cls: 0.8706) LR: 0.000044
Batch 40: Loss 1.0512 (Cls: 0.7850) LR: 0.000044
Batch 50: Loss 0.9835 (Cls: 0.7336) LR: 0.000043
Batch 60: Loss 1.0678 (Cls: 0.8304) LR: 0.000043
Batch 70: Loss 1.1179 (Cls: 0.8537) LR: 0.000043
Batch 80: Loss 1.1156 (Cls: 0.8520) LR: 0.000042
Epoch 48: Loss 1.0427, Acc 0.6015
Val Loss 1.3019, Val Acc 0.5942
Batch 0: Loss 1.1188 (Cls: 0.8455) LR: 0.000042
Batch 10: Loss 0.9705 (Cls: 0.7344) LR: 0.000042
Batch 20: Loss 0.9326 (Cls: 0.7008) LR: 0.000041
Batch 30: Loss 1.0869 (Cls: 0.8336) LR: 0.000041
Batch 40: Loss 0.9800 (Cls: 0.7415) LR: 0.000040
Batch 50: Loss 1.0737 (Cls: 0.8026) LR: 0.000040
Batch 60: Loss 1.0308 (Cls: 0.8024) LR: 0.000040
Batch 70: Loss 1.0236 (Cls: 0.7841) LR: 0.000039
Batch 80: Loss 0.9136 (Cls: 0.6469) LR: 0.000039
Epoch 49: Loss 1.0419, Acc 0.5980
Val Loss 1.2567, Val Acc 0.6360
New best model saved with Val Acc: 0.6360
Batch 0: Loss 1.0662 (Cls: 0.7991) LR: 0.000039
Batch 10: Loss 1.1584 (Cls: 0.8642) LR: 0.000038
Batch 20: Loss 1.0840 (Cls: 0.8015) LR: 0.000038
Batch 30: Loss 1.0114 (Cls: 0.7683) LR: 0.000038
Batch 40: Loss 1.1781 (Cls: 0.8946) LR: 0.000037
Batch 50: Loss 0.9793 (Cls: 0.7425) LR: 0.000037
Batch 60: Loss 1.0311 (Cls: 0.7742) LR: 0.000037
Batch 70: Loss 1.1035 (Cls: 0.8371) LR: 0.000036
Batch 80: Loss 1.0456 (Cls: 0.7942) LR: 0.000036
Epoch 50: Loss 1.0334, Acc 0.6069
Val Loss 1.3079, Val Acc 0.6056
Batch 0: Loss 1.1171 (Cls: 0.8406) LR: 0.000036
Batch 10: Loss 1.0368 (Cls: 0.7915) LR: 0.000035
Batch 20: Loss 0.9802 (Cls: 0.7015) LR: 0.000035
Batch 30: Loss 1.0294 (Cls: 0.7644) LR: 0.000035
Batch 40: Loss 1.1464 (Cls: 0.8831) LR: 0.000034
Batch 50: Loss 0.9307 (Cls: 0.6886) LR: 0.000034
Batch 60: Loss 0.9509 (Cls: 0.7280) LR: 0.000034
Batch 70: Loss 0.9521 (Cls: 0.7080) LR: 0.000033
Batch 80: Loss 0.9991 (Cls: 0.7494) LR: 0.000033
Epoch 51: Loss 1.0202, Acc 0.6156
Val Loss 1.2769, Val Acc 0.6125
Batch 0: Loss 1.0985 (Cls: 0.8473) LR: 0.000033
Batch 10: Loss 1.0970 (Cls: 0.8449) LR: 0.000032
Batch 20: Loss 1.0097 (Cls: 0.7482) LR: 0.000032
Batch 30: Loss 1.0627 (Cls: 0.7781) LR: 0.000032
Batch 40: Loss 1.1387 (Cls: 0.8949) LR: 0.000031
Batch 50: Loss 0.9588 (Cls: 0.7079) LR: 0.000031
Batch 60: Loss 0.9546 (Cls: 0.7306) LR: 0.000031
Batch 70: Loss 0.9140 (Cls: 0.7002) LR: 0.000030
Batch 80: Loss 0.9757 (Cls: 0.7661) LR: 0.000030
Epoch 52: Loss 1.0110, Acc 0.6171
Val Loss 1.3342, Val Acc 0.5638
Batch 0: Loss 0.9071 (Cls: 0.7068) LR: 0.000030
Batch 10: Loss 0.9419 (Cls: 0.7058) LR: 0.000029
Batch 20: Loss 1.0428 (Cls: 0.7978) LR: 0.000029
Batch 30: Loss 0.9705 (Cls: 0.7680) LR: 0.000029
Batch 40: Loss 1.0623 (Cls: 0.8245) LR: 0.000028
Batch 50: Loss 1.1355 (Cls: 0.8663) LR: 0.000028
Batch 60: Loss 0.9554 (Cls: 0.7263) LR: 0.000028
Batch 70: Loss 1.0908 (Cls: 0.8233) LR: 0.000027
Batch 80: Loss 0.9818 (Cls: 0.7453) LR: 0.000027
Epoch 53: Loss 0.9995, Acc 0.6303
Val Loss 1.2693, Val Acc 0.6231
Batch 0: Loss 0.9162 (Cls: 0.7246) LR: 0.000027
Batch 10: Loss 1.0235 (Cls: 0.7592) LR: 0.000026
Batch 20: Loss 0.9644 (Cls: 0.7489) LR: 0.000026
Batch 30: Loss 0.8927 (Cls: 0.6867) LR: 0.000026
Batch 40: Loss 0.9870 (Cls: 0.7516) LR: 0.000025
Batch 50: Loss 1.0705 (Cls: 0.8065) LR: 0.000025
Batch 60: Loss 1.0175 (Cls: 0.7594) LR: 0.000025
Batch 70: Loss 0.9425 (Cls: 0.6952) LR: 0.000025
Batch 80: Loss 1.0001 (Cls: 0.7701) LR: 0.000024
Epoch 54: Loss 0.9896, Acc 0.6403
Val Loss 1.3174, Val Acc 0.5760
Batch 0: Loss 1.0055 (Cls: 0.7739) LR: 0.000024
Batch 10: Loss 0.9404 (Cls: 0.7161) LR: 0.000024
Batch 20: Loss 1.0602 (Cls: 0.8247) LR: 0.000023
Batch 30: Loss 0.9732 (Cls: 0.7327) LR: 0.000023
Batch 40: Loss 0.9767 (Cls: 0.7509) LR: 0.000023
Batch 50: Loss 1.0562 (Cls: 0.7899) LR: 0.000022
Batch 60: Loss 1.0484 (Cls: 0.7886) LR: 0.000022
Batch 70: Loss 1.0833 (Cls: 0.8306) LR: 0.000022
Batch 80: Loss 0.9311 (Cls: 0.7122) LR: 0.000021
Epoch 55: Loss 0.9825, Acc 0.6410
Val Loss 1.2694, Val Acc 0.6163
Batch 0: Loss 1.0212 (Cls: 0.7814) LR: 0.000021
Batch 10: Loss 0.9521 (Cls: 0.7226) LR: 0.000021
Batch 20: Loss 0.9571 (Cls: 0.7392) LR: 0.000021
Batch 30: Loss 0.9183 (Cls: 0.7097) LR: 0.000020
Batch 40: Loss 0.9287 (Cls: 0.7006) LR: 0.000020
Batch 50: Loss 0.9623 (Cls: 0.7258) LR: 0.000020
Batch 60: Loss 0.9794 (Cls: 0.7290) LR: 0.000020
Batch 70: Loss 1.0209 (Cls: 0.7819) LR: 0.000019
Batch 80: Loss 0.9004 (Cls: 0.6877) LR: 0.000019
Epoch 56: Loss 0.9718, Acc 0.6501
Val Loss 1.2415, Val Acc 0.6527
New best model saved with Val Acc: 0.6527
Batch 0: Loss 0.9783 (Cls: 0.7561) LR: 0.000019
Batch 10: Loss 0.8744 (Cls: 0.6387) LR: 0.000018
Batch 20: Loss 0.9191 (Cls: 0.7113) LR: 0.000018
Batch 30: Loss 0.9946 (Cls: 0.7701) LR: 0.000018
Batch 40: Loss 0.9837 (Cls: 0.7410) LR: 0.000018
Batch 50: Loss 0.9488 (Cls: 0.6955) LR: 0.000017
Batch 60: Loss 0.9502 (Cls: 0.7365) LR: 0.000017
Batch 70: Loss 1.0483 (Cls: 0.7861) LR: 0.000017
Batch 80: Loss 1.0222 (Cls: 0.7865) LR: 0.000016
Epoch 57: Loss 0.9638, Acc 0.6553
Val Loss 1.2743, Val Acc 0.6193
Batch 0: Loss 0.9239 (Cls: 0.6770) LR: 0.000016
Batch 10: Loss 1.0268 (Cls: 0.7873) LR: 0.000016
Batch 20: Loss 1.0169 (Cls: 0.7697) LR: 0.000016
Batch 30: Loss 0.9355 (Cls: 0.7161) LR: 0.000016
Batch 40: Loss 0.9271 (Cls: 0.6889) LR: 0.000015
Batch 50: Loss 0.9041 (Cls: 0.6960) LR: 0.000015
Batch 60: Loss 1.0378 (Cls: 0.7864) LR: 0.000015
Batch 70: Loss 0.9959 (Cls: 0.7718) LR: 0.000014
Batch 80: Loss 0.8844 (Cls: 0.6705) LR: 0.000014
Epoch 58: Loss 0.9596, Acc 0.6471
Val Loss 1.2568, Val Acc 0.6345
Batch 0: Loss 0.9622 (Cls: 0.7149) LR: 0.000014
Batch 10: Loss 1.0220 (Cls: 0.7853) LR: 0.000014
Batch 20: Loss 1.0078 (Cls: 0.7427) LR: 0.000014
Batch 30: Loss 0.9817 (Cls: 0.7320) LR: 0.000013
Batch 40: Loss 1.2226 (Cls: 0.9460) LR: 0.000013
Batch 50: Loss 1.0287 (Cls: 0.7875) LR: 0.000013
Batch 60: Loss 1.0473 (Cls: 0.8142) LR: 0.000012
Batch 70: Loss 0.9079 (Cls: 0.6730) LR: 0.000012
Batch 80: Loss 0.9833 (Cls: 0.7305) LR: 0.000012
Epoch 59: Loss 0.9684, Acc 0.6597
Val Loss 1.2937, Val Acc 0.6071
Batch 0: Loss 0.9709 (Cls: 0.7172) LR: 0.000012
Batch 10: Loss 0.9921 (Cls: 0.7584) LR: 0.000012
Batch 20: Loss 0.9548 (Cls: 0.7241) LR: 0.000011
Batch 30: Loss 0.8993 (Cls: 0.6619) LR: 0.000011
Batch 40: Loss 0.9752 (Cls: 0.7236) LR: 0.000011
Batch 50: Loss 0.9193 (Cls: 0.7039) LR: 0.000011
Batch 60: Loss 1.0077 (Cls: 0.7708) LR: 0.000010
Batch 70: Loss 0.9999 (Cls: 0.7765) LR: 0.000010
Batch 80: Loss 0.8747 (Cls: 0.6688) LR: 0.000010
Epoch 60: Loss 0.9378, Acc 0.6698
Val Loss 1.2487, Val Acc 0.6436
Batch 0: Loss 1.0068 (Cls: 0.7605) LR: 0.000010
Batch 10: Loss 0.9858 (Cls: 0.7532) LR: 0.000010
Batch 20: Loss 0.9427 (Cls: 0.7046) LR: 0.000009
Batch 30: Loss 0.8765 (Cls: 0.6428) LR: 0.000009
Batch 40: Loss 0.9872 (Cls: 0.7398) LR: 0.000009
Batch 50: Loss 0.9543 (Cls: 0.7406) LR: 0.000009
Batch 60: Loss 1.0558 (Cls: 0.7980) LR: 0.000009
Batch 70: Loss 0.9105 (Cls: 0.6850) LR: 0.000008
Batch 80: Loss 0.9356 (Cls: 0.7161) LR: 0.000008
Epoch 61: Loss 0.9521, Acc 0.6605
Val Loss 1.2825, Val Acc 0.6117
Batch 0: Loss 0.9647 (Cls: 0.7312) LR: 0.000008
Batch 10: Loss 0.9351 (Cls: 0.6992) LR: 0.000008
Batch 20: Loss 0.8711 (Cls: 0.6336) LR: 0.000008
Batch 30: Loss 0.9557 (Cls: 0.7282) LR: 0.000007
Batch 40: Loss 0.9870 (Cls: 0.7497) LR: 0.000007
Batch 50: Loss 0.9231 (Cls: 0.6772) LR: 0.000007
Batch 60: Loss 1.0485 (Cls: 0.7969) LR: 0.000007
Batch 70: Loss 1.0675 (Cls: 0.8156) LR: 0.000007
Batch 80: Loss 0.8168 (Cls: 0.6365) LR: 0.000006
Epoch 62: Loss 0.9461, Acc 0.6722
Val Loss 1.2607, Val Acc 0.6368
Batch 0: Loss 0.9356 (Cls: 0.7128) LR: 0.000006
Batch 10: Loss 0.9621 (Cls: 0.7163) LR: 0.000006
Batch 20: Loss 0.9769 (Cls: 0.7302) LR: 0.000006
Batch 30: Loss 0.8964 (Cls: 0.6890) LR: 0.000006
Batch 40: Loss 0.9005 (Cls: 0.6800) LR: 0.000006
Batch 50: Loss 0.9813 (Cls: 0.7692) LR: 0.000006
Batch 60: Loss 0.9618 (Cls: 0.7047) LR: 0.000005
Batch 70: Loss 0.8774 (Cls: 0.6683) LR: 0.000005
Batch 80: Loss 0.9437 (Cls: 0.7150) LR: 0.000005
Epoch 63: Loss 0.9469, Acc 0.6638
Val Loss 1.2511, Val Acc 0.6482
Batch 0: Loss 0.9832 (Cls: 0.7448) LR: 0.000005
Batch 10: Loss 0.9420 (Cls: 0.7205) LR: 0.000005
Batch 20: Loss 0.9267 (Cls: 0.6624) LR: 0.000005
Batch 30: Loss 0.8728 (Cls: 0.6639) LR: 0.000004
Batch 40: Loss 0.9402 (Cls: 0.6914) LR: 0.000004
Batch 50: Loss 1.0209 (Cls: 0.7916) LR: 0.000004
Batch 60: Loss 0.8411 (Cls: 0.6464) LR: 0.000004
Batch 70: Loss 0.9172 (Cls: 0.7175) LR: 0.000004
Batch 80: Loss 1.0189 (Cls: 0.7905) LR: 0.000004
Epoch 64: Loss 0.9363, Acc 0.6772
Val Loss 1.2607, Val Acc 0.6360
Batch 0: Loss 1.0150 (Cls: 0.7707) LR: 0.000004
Batch 10: Loss 0.8224 (Cls: 0.6160) LR: 0.000003
Batch 20: Loss 0.9072 (Cls: 0.7058) LR: 0.000003
Batch 30: Loss 0.9593 (Cls: 0.7449) LR: 0.000003
Batch 40: Loss 0.9747 (Cls: 0.7411) LR: 0.000003
Batch 50: Loss 0.8309 (Cls: 0.6258) LR: 0.000003
Batch 60: Loss 0.8666 (Cls: 0.6668) LR: 0.000003
Batch 70: Loss 0.8800 (Cls: 0.6600) LR: 0.000003
Batch 80: Loss 0.8811 (Cls: 0.6563) LR: 0.000003
Epoch 65: Loss 0.9213, Acc 0.6820
Val Loss 1.2704, Val Acc 0.6292
Batch 0: Loss 0.9811 (Cls: 0.7431) LR: 0.000003
Batch 10: Loss 0.9519 (Cls: 0.7356) LR: 0.000002
Batch 20: Loss 0.9196 (Cls: 0.6945) LR: 0.000002
Batch 30: Loss 0.9046 (Cls: 0.6720) LR: 0.000002
Batch 40: Loss 0.8527 (Cls: 0.6331) LR: 0.000002
Batch 50: Loss 0.9480 (Cls: 0.7235) LR: 0.000002
Batch 60: Loss 0.8270 (Cls: 0.6065) LR: 0.000002
Batch 70: Loss 0.9606 (Cls: 0.7345) LR: 0.000002
Batch 80: Loss 0.9253 (Cls: 0.6971) LR: 0.000002
Epoch 66: Loss 0.9336, Acc 0.6753
Val Loss 1.2641, Val Acc 0.6360
Batch 0: Loss 0.9498 (Cls: 0.7269) LR: 0.000002
Batch 10: Loss 0.9525 (Cls: 0.7219) LR: 0.000002
Batch 20: Loss 0.8879 (Cls: 0.6734) LR: 0.000001
Batch 30: Loss 0.9098 (Cls: 0.6808) LR: 0.000001
Batch 40: Loss 0.9039 (Cls: 0.6728) LR: 0.000001
Batch 50: Loss 0.9734 (Cls: 0.7445) LR: 0.000001
Batch 60: Loss 0.9999 (Cls: 0.7556) LR: 0.000001
Batch 70: Loss 0.9036 (Cls: 0.6600) LR: 0.000001
Batch 80: Loss 0.9593 (Cls: 0.7336) LR: 0.000001
Epoch 67: Loss 0.9309, Acc 0.6785
Val Loss 1.2449, Val Acc 0.6451
Batch 0: Loss 0.9109 (Cls: 0.7087) LR: 0.000001
Batch 10: Loss 0.8836 (Cls: 0.6667) LR: 0.000001
Batch 20: Loss 0.9293 (Cls: 0.6922) LR: 0.000001
Batch 30: Loss 0.8519 (Cls: 0.6633) LR: 0.000001
Batch 40: Loss 0.9030 (Cls: 0.6774) LR: 0.000001
Batch 50: Loss 0.9937 (Cls: 0.7502) LR: 0.000001
Batch 60: Loss 0.9832 (Cls: 0.7379) LR: 0.000001
Batch 70: Loss 0.8584 (Cls: 0.6407) LR: 0.000000
Batch 80: Loss 0.9267 (Cls: 0.7050) LR: 0.000000
Epoch 68: Loss 0.9286, Acc 0.6779
Val Loss 1.2534, Val Acc 0.6383
Batch 0: Loss 0.9041 (Cls: 0.7014) LR: 0.000000
Batch 10: Loss 0.9998 (Cls: 0.7614) LR: 0.000000
Batch 20: Loss 0.9616 (Cls: 0.7237) LR: 0.000000
Batch 30: Loss 0.9484 (Cls: 0.7238) LR: 0.000000
Batch 40: Loss 0.9647 (Cls: 0.7485) LR: 0.000000
Batch 50: Loss 0.9417 (Cls: 0.7035) LR: 0.000000
Batch 60: Loss 0.8690 (Cls: 0.6492) LR: 0.000000
Batch 70: Loss 0.9585 (Cls: 0.7157) LR: 0.000000
Batch 80: Loss 0.9886 (Cls: 0.7303) LR: 0.000000
Epoch 69: Loss 0.9264, Acc 0.6833
Val Loss 1.2532, Val Acc 0.6383
Batch 0: Loss 0.9016 (Cls: 0.6358) LR: 0.000000
Batch 10: Loss 0.9377 (Cls: 0.7034) LR: 0.000000
Batch 20: Loss 1.0467 (Cls: 0.8014) LR: 0.000000
Batch 30: Loss 0.8259 (Cls: 0.6068) LR: 0.000000
Batch 40: Loss 0.9123 (Cls: 0.6715) LR: 0.000000
Batch 50: Loss 0.9400 (Cls: 0.6944) LR: 0.000000
Batch 60: Loss 0.8626 (Cls: 0.6626) LR: 0.000000
Batch 70: Loss 0.8729 (Cls: 0.6598) LR: 0.000000
Batch 80: Loss 0.8972 (Cls: 0.6759) LR: 0.000000
Epoch 70: Loss 0.9269, Acc 0.6827
Val Loss 1.2531, Val Acc 0.6375
Running Test Evaluation...
/root/shared-nvme/fire/src/training/train.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(best_model_path))
Traceback (most recent call last):
  File "/root/miniconda3/envs/fire/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/miniconda3/envs/fire/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/root/shared-nvme/fire/src/training/train.py", line 380, in <module>
    main(args.config, args.exp_name)
  File "/root/shared-nvme/fire/src/training/train.py", line 349, in main
    model.load_state_dict(torch.load(best_model_path))
  File "/root/miniconda3/envs/fire/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for FireDamageClassifier:
	While copying the parameter named "sentence_encoder.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.word_embeddings.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.word_embeddings.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.position_embeddings.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.position_embeddings.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.token_type_embeddings.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.embeddings.token_type_embeddings.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.0.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.1.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.2.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.3.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.4.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.self.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.self.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.attention.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.intermediate.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.intermediate.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.intermediate.intermediate_act_fn.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.intermediate.intermediate_act_fn.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.output.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.encoder.layer.5.output.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.pooler.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.pooler.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.pooler.activation.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.0.auto_model.pooler.activation.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.1.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.1.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.2.total_ops", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
	While copying the parameter named "sentence_encoder.2.total_params", whose dimensions in the model are torch.Size([1]) and whose dimensions in the checkpoint are torch.Size([1]), an exception occurred : ('Inplace update to inference tensor outside InferenceMode is not allowed.You can make a clone to get a normal tensor before doing inplace update.See https://github.com/pytorch/rfcs/pull/17 for more details.',).
